<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Lexieye â€“ Live Pill Counter (camera view + overlay)</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet" />
  <style>
    :root{--primary:#007acc;--accent:#d9eaff;--bg:#fdfefe;--glass:rgba(255,255,255,0.2);--border-glass:rgba(255,255,255,0.4);--text:#333}
    *{box-sizing:border-box}
    body{font-family:Poppins,system-ui,Segoe UI,Arial,sans-serif;background:radial-gradient(circle at 40% 40%,var(--bg),#e0f4ff);color:var(--text);margin:0;padding:20px}
    h1{ text-align:center; font-size:2.4rem; color:var(--primary); margin:0 0 16px }
    .wrap{ max-width:1000px; margin:auto; border-radius:28px; padding:20px; background:var(--glass); border:1px solid var(--border-glass); backdrop-filter:blur(30px) }
    .controls{ display:flex; gap:12px; align-items:center; flex-wrap:wrap; margin-top:12px }
    .btn{ background:var(--primary); color:#fff; border:none; border-radius:20px; padding:10px 16px; cursor:pointer }
    .btn[disabled]{ opacity:.6; cursor:not-allowed }
    .pill{ display:inline-block; padding:2px 6px; border-radius:12px; background:#e8f4ff; border:1px solid #cfe7ff }
    .err{ color:#b00020; font-size:.95rem }
    .feed{ position:relative; width:100%; }
    video{ width:100%; border-radius:18px; border:2px solid var(--primary); display:block }
    /* Transparent overlay just for drawings */
    #overlay{ position:absolute; inset:0; width:100%; height:100%; pointer-events:none; border-radius:18px; }
  </style>
</head>
<body>
  <h1>ðŸ’Š Lexieye â€“ Live Pill Counter</h1>

  <div class="wrap">
    <div class="controls">
      <button id="startBtn" class="btn">Enable Camera & Start</button>
      <span class="pill">Detected: <b id="count">0</b></span>
      <span class="pill" id="fps">0 fps</span>
    </div>
    <div class="err" id="err"></div>

    <!-- Camera view kept. Only the captured IMAGE layer is removed; we draw on a transparent overlay. -->
    <div class="feed">
      <video id="video" autoplay playsinline muted></video>
      <canvas id="overlay"></canvas>
    </div>
  </div>

  <script>
    // Camera-visible UI with transparent overlay; no second still image.
    const startBtn=document.getElementById('startBtn');
    const errEl=document.getElementById('err');
    const video=document.getElementById('video');
    const overlay=document.getElementById('overlay');
    const octx=overlay.getContext('2d');
    const countEl=document.getElementById('count');
    const fpsEl=document.getElementById('fps');

    let stream=null, running=false, lastTick=performance.now(), frames=0, warmup=30, frameIndex=0;
    let recentCounts=[]; // median smoothing

    // Offscreen work canvas for OpenCV (processing only)
    const work=document.createElement('canvas');
    const wctx=work.getContext('2d');

    // OpenCV Mats
    let src, gray, blur, mask, morph, edges, kernel, contours, hierarchy, dt, markers;
    let clahe=null; // contrast enhancer

    function showErr(msg){ errEl.textContent=msg; console.error(msg); }
    function secureContextCheck(){
      if (location.protocol!=='https:' && location.hostname!=='localhost' && location.hostname!=='127.0.0.1'){
        showErr('Camera requires HTTPS or localhost.');
      }
    }

    async function startCamera(){
      errEl.textContent='';
      const tries=[
        {video:{facingMode:{ideal:'environment'}, width:{ideal:1920}, height:{ideal:1080}}, audio:false},
        {video:{facingMode:{ideal:'environment'}, width:{ideal:1280}, height:{ideal:720}}, audio:false},
        {video:true, audio:false}
      ];
      try{
        const devs=await navigator.mediaDevices.enumerateDevices();
        const back=devs.find(d=>d.kind==='videoinput' && /back|environment/i.test(d.label||''));
        if(back) tries.unshift({video:{deviceId:{exact:back.deviceId}, width:{ideal:1920}, height:{ideal:1080}}, audio:false});
      }catch{}
      for(const c of tries){
        try{
          stream=await navigator.mediaDevices.getUserMedia(c);
          video.srcObject=stream; video.setAttribute('playsinline','true'); await video.play();

          // Improve exposure/white balance/torch if supported
          const track = stream.getVideoTracks()[0];
          const caps  = track.getCapabilities ? track.getCapabilities() : {};
          const adv = [];
          if (caps.exposureMode) adv.push({ exposureMode:'continuous' });
          if (caps.whiteBalanceMode) adv.push({ whiteBalanceMode:'continuous' });
          if (caps.brightness) adv.push({ brightness: caps.brightness.max || 0 });
          if (caps.exposureCompensation) adv.push({ exposureCompensation: caps.exposureCompensation.max });
          if (caps.torch) adv.push({ torch:true }); // mobile back camera
          if (adv.length) { track.applyConstraints({ advanced: adv }).catch(()=>{}); }
          return true;
        }catch(e){ console.warn('gUM fail',c,e); }
      }
      showErr('Could not start the camera.');
      return false;
    }

    function initMats(w,h){
      [src,gray,blur,mask,morph,edges,kernel,contours,hierarchy,dt,markers].forEach(m=>{ try{ m&&m.delete(); }catch{} });
      if (clahe){ try{ clahe.delete(); }catch{}; clahe=null; }
      src=new cv.Mat(h,w,cv.CV_8UC4);
      gray=new cv.Mat(h,w,cv.CV_8UC1);
      blur=new cv.Mat(h,w,cv.CV_8UC1);
      mask=new cv.Mat(h,w,cv.CV_8UC1);
      morph=new cv.Mat(h,w,cv.CV_8UC1);
      edges=new cv.Mat(h,w,cv.CV_8UC1);
      dt=new cv.Mat(h,w,cv.CV_32F);
      markers=new cv.Mat(h,w,cv.CV_32S);
      kernel=cv.getStructuringElement(cv.MORPH_ELLIPSE, new cv.Size(5,5));
      contours=new cv.MatVector();
      hierarchy=new cv.Mat();
      try { clahe = cv.createCLAHE(2.0, new cv.Size(8,8)); } catch { clahe = null; }
    }

    function median(arr){ const a=[...arr].sort((x,y)=>x-y); const m=Math.floor(a.length/2); return a.length%2?a[m]:(a[m-1]+a[m])/2; }
    function updateFps(){ frames++; const now=performance.now(); if(now-lastTick>=1000){ fpsEl.textContent=`${frames} fps`; frames=0; lastTick=now; } }

    // --- AUTO CALIBRATION LOGIC ---
    const auto = { invert:false, minAreaPx:200, maxAreaPx:20000 };

    function autoBrighten(intensityMean){
      if (intensityMean < 60) { cv.convertScaleAbs(gray, gray, 1.6, 12); }
      else if (intensityMean < 90) { cv.convertScaleAbs(gray, gray, 1.3, 6); }
      try { if (clahe) { clahe.apply(gray, gray); } else { cv.equalizeHist(gray, gray); } } catch {}
    }

    function choosePolarityAndThreshold(){
      const tests = [cv.THRESH_BINARY+cv.THRESH_OTSU, cv.THRESH_BINARY_INV+cv.THRESH_OTSU];
      let best={score:-1, invert:false, mask:null};
      for(const t of tests){
        const tmp=new cv.Mat();
        cv.threshold(blur, tmp, 0, 255, t);
        const cleaned=new cv.Mat();
        cv.morphologyEx(tmp, cleaned, cv.MORPH_OPEN, kernel);
        cv.morphologyEx(cleaned, cleaned, cv.MORPH_CLOSE, kernel);
        const vec=new cv.MatVector(), hier=new cv.Mat();
        cv.findContours(cleaned, vec, hier, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
        const total = cleaned.rows*cleaned.cols; const lo=total*0.0015, hi=total*0.35;
        let good=0; let areas=[];
        for(let i=0;i<vec.size();i++){ const a=cv.contourArea(vec.get(i)); if(a>lo && a<hi){ good++; areas.push(a); } }
        if(good>best.score){ if(best.mask) best.mask.delete(); best={score:good, invert:(t&cv.THRESH_BINARY_INV)!==0, mask:cleaned}; }
        else { cleaned.delete(); }
        tmp.delete(); vec.delete(); hier.delete();
      }
      auto.invert = best.invert;
      mask.delete(); mask = best.mask;

      // Dynamic area bounds 10thâ€“90th percentile
      const vec2=new cv.MatVector(), hier2=new cv.Mat();
      cv.findContours(mask, vec2, hier2, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      let areas=[]; for(let i=0;i<vec2.size();i++){ areas.push(cv.contourArea(vec2.get(i))); }
      areas.sort((a,b)=>a-b);
      if(areas.length){ const q=p=>areas[Math.max(0,Math.min(areas.length-1,Math.floor(p*(areas.length-1))))]; auto.minAreaPx=Math.max(40,q(0.10)); auto.maxAreaPx=Math.max(auto.minAreaPx+80,q(0.90)); }
      vec2.delete(); hier2.delete();
    }

    function scaleOverlayToVideo(){
      const w=video.videoWidth||640, h=video.videoHeight||480;
      const dpr = window.devicePixelRatio || 1;
      // CSS size matches video element size; canvas internal pixels scaled by dpr
      const rect = video.getBoundingClientRect();
      overlay.style.width = rect.width + 'px';
      overlay.style.height = rect.height + 'px';
      overlay.width = Math.round(w * dpr);
      overlay.height = Math.round(h * dpr);
      octx.setTransform(dpr,0,0,dpr,0,0); // draw in video pixel coords
      // work/offscreen
      work.width = w; work.height = h;
      initMats(w,h);
    }

    function processFrame(){
      if(!running) return;
      const w=video.videoWidth||640, h=video.videoHeight||480;
      if(!w||!h){ requestAnimationFrame(processFrame); return; }
      if (work.width !== w || work.height !== h) { scaleOverlayToVideo(); }

      // Draw the live video frame into the OFFSCREEN work canvas
      wctx.drawImage(video,0,0,w,h);
      cv.imread(work, src);
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

      // Auto brighten & contrast if dark
      const meanScalar = cv.mean(gray);
      autoBrighten(meanScalar[0]);

      // Denoise
      cv.GaussianBlur(gray, blur, new cv.Size(5,5), 1.1, 1.1);

      // Auto-calibrate periodically and during warm-up
      if (frameIndex < warmup || frameIndex % 30 === 0){
        choosePolarityAndThreshold();
      } else {
        const type=(auto.invert?cv.THRESH_BINARY_INV:cv.THRESH_BINARY)+cv.THRESH_OTSU;
        cv.threshold(blur, mask, 0, 255, type);
        cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel);
        cv.morphologyEx(mask, mask, cv.MORPH_CLOSE, kernel);
      }

      // Optional splitting of touching pills using distance transform (lightweight)
      cv.distanceTransform(mask, dt, cv.DIST_L2, 3);
      const dtNorm = new cv.Mat();
      cv.normalize(dt, dtNorm, 0, 1.0, cv.NORM_MINMAX);
      const fg = new cv.Mat();
      cv.threshold(dtNorm, fg, 0.35, 1.0, cv.THRESH_BINARY);
      fg.convertTo(fg, cv.CV_8U, 255);

      // Final mask for contouring: intersect foreground with original mask to keep shapes
      const finalMask = new cv.Mat();
      cv.bitwise_and(mask, fg, finalMask);

      // Find pills and collect their centers for overlay
      cv.findContours(finalMask, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      let count=0; const dots=[]; const rings=[];
      for(let i=0;i<contours.size();i++){
        const cnt=contours.get(i); const area=cv.contourArea(cnt);
        if(area<auto.minAreaPx || area>auto.maxAreaPx){ cnt.delete(); continue; }
        const peri=cv.arcLength(cnt,true);
        const circ=(4*Math.PI*area)/(peri*peri+1e-6);
        const hull=new cv.Mat(); cv.convexHull(cnt,hull);
        const solid=area/Math.max(cv.contourArea(hull),1e-6);
        if(circ>=0.42 && solid>=0.78){
          const M=cv.moments(cnt); const cx=M.m10/(M.m00||1), cy=M.m01/(M.m00||1);
          const r=Math.max(4, Math.sqrt(area/Math.PI)|0);
          dots.push({cx,cy}); rings.push({cx,cy,r}); count++;
        }
        hull.delete(); cnt.delete();
      }

      // Draw overlay (transparent) on top of the live video
      octx.clearRect(0,0,overlay.width, overlay.height);
      octx.lineWidth = 3; octx.strokeStyle = 'rgba(0,255,0,0.95)';
      for(const {cx,cy,r} of rings){ octx.beginPath(); octx.arc(cx, cy, r, 0, Math.PI*2); octx.stroke(); }
      // Center DOT on each pill
      octx.fillStyle = 'rgba(255,0,0,0.95)';
      for(const {cx,cy} of dots){ octx.beginPath(); octx.arc(cx, cy, 4, 0, Math.PI*2); octx.fill(); }

      // Stable count via median of last 7 frames
      recentCounts.push(count); if(recentCounts.length>7) recentCounts.shift();
      countEl.textContent = median(recentCounts);

      updateFps(); frameIndex++;
      dtNorm.delete(); fg.delete(); finalMask.delete();
      requestAnimationFrame(processFrame);
    }

    function setRunning(on){ running=on; if(on) requestAnimationFrame(processFrame); }

    // Only enable Start after OpenCV is ready
    window.cv=window.cv||{};
    cv['onRuntimeInitialized']=()=>{ startBtn.disabled=false; console.log('OpenCV ready'); };

    startBtn.addEventListener('click', async()=>{
      secureContextCheck();
      startBtn.disabled=true;
      const ok=await startCamera();
      if(ok){ scaleOverlayToVideo(); setRunning(true); } else { startBtn.disabled=false; }
    });

    // Cleanup
    window.addEventListener('beforeunload', ()=>{ try{stream&&stream.getTracks().forEach(t=>t.stop())}catch{}; [src,gray,blur,mask,morph,edges,kernel,contours,hierarchy,dt,markers].forEach(m=>{try{m&&m.delete()}catch{}}); if(clahe){try{clahe.delete()}catch{}} });

    secureContextCheck();
  </script>
</body>
</html>
